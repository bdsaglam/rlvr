# ==============================================================================
# Core
# ==============================================================================

max_steps = 500
seq_len = 32768
inference_gpu_ids = [0, 1, 2]
trainer_gpu_ids = [3]

[model]
name = "willcb/Qwen3-8B"

# ==============================================================================
# Trainer
# ==============================================================================

[trainer.optim]
lr = 1e-6
weight_decay = 0.0

[trainer.tokenizer]
name = "willcb/Qwen3-8B"

[trainer.model.ac]
freq = 1

[trainer.model.lora]
rank = 32
alpha = 32
dropout = 0.05
target_modules = ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# ==============================================================================
# Orchestrator
# ==============================================================================

[orchestrator]
batch_size = 128
rollouts_per_example = 16
oversampling_factor = 2.0
max_concurrent = 64

[orchestrator.sampling]
max_tokens = 16384
temperature = 0.6

[orchestrator.wandb.log_extras]
samples = true
distributions = true
interval = 10

# ==============================================================================
# Environment
# ==============================================================================

[[orchestrator.env]]
id = "arc-agi"
args = { dataset_name = "arc-prize-2024", eval_dataset_name = "arc-prize-2024", eval_split = "evaluation", reward_mode = "balanced", max_turns = 40 }

# ==============================================================================
# Evaluation
# ==============================================================================

[orchestrator.eval]
interval = 100
rollouts_per_example = 4
num_examples = 16

[[orchestrator.eval.env]]
id = "arc-agi"
args = { dataset_name = "arc-prize-2024", eval_dataset_name = "arc-prize-2024", eval_split = "evaluation", reward_mode = "balanced", max_turns = 40 }

# ==============================================================================
# Inference
# ==============================================================================

[inference]
gpu_memory_utilization = 0.4

[inference.model]
name = "willcb/Qwen3-8B"
max_model_len = 32768
dtype = "bfloat16"
enable_auto_tool_choice = true
tool_call_parser = "hermes"
reasoning_parser = "qwen3"

# ==============================================================================
# Weights & Biases
# ==============================================================================

[wandb]
project = "rlvr-arc-agi"
name = "repl-qwen3-8b"
