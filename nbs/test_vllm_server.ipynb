{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vLLM Server Test\n",
    "\n",
    "This notebook tests the vLLM server running with Llama-3.1-8B-Instruct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# dependencies = [\n",
    "#   \"httpx\",\n",
    "#   \"openai\",\n",
    "# ]\n",
    "# ///\n",
    "\n",
    "import httpx\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from openai import OpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server configuration\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "client = OpenAI(base_url=f\"{BASE_URL}/v1\", api_key=\"token-abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health check status: 200\n",
      "Available models: ['Qwen/Qwen3-8B']\n",
      "Using model: Qwen/Qwen3-8B\n"
     ]
    }
   ],
   "source": [
    "# Check server health\n",
    "with httpx.Client() as http_client:\n",
    "    health_response = http_client.get(f\"{BASE_URL}/health\", timeout=5)\n",
    "    print(f\"Health check status: {health_response.status_code}\")\n",
    "    \n",
    "# Get available models using OpenAI client\n",
    "models = client.models.list()\n",
    "available_models = [model.id for model in models.data]\n",
    "print(\"Available models:\", available_models)\n",
    "\n",
    "DEFAULT_MODEL = available_models[0] if available_models else \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "print(f\"Using model: {DEFAULT_MODEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_chat_completion(\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int | None = None,\n",
    "    model: str = DEFAULT_MODEL,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Send a chat completion request using OpenAI client.\n",
    "\n",
    "    Args:\n",
    "        messages: List of message dictionaries with 'role' and 'content'\n",
    "        temperature: Sampling temperature (0.0 to 1.0)\n",
    "        max_tokens: Maximum number of tokens to generate\n",
    "        model: Model to use for completion\n",
    "\n",
    "    Returns:\n",
    "        Response dictionary from the server\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return response.model_dump()\n",
    "    except Exception as e:\n",
    "        print(f\"Chat completion failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Simple greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "{\n",
      "  \"id\": \"chatcmpl-3d8425af84024b089a7c8d918b5d5a3d\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\n\\nHello! I'm just a friendly AI assistant, so I don't have feelings, but I'm here and ready to help! \\ud83d\\ude0a How are you today? I'd love to hear how your day is going!\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": [],\n",
      "        \"reasoning_content\": \"\\nOkay, the user greeted me with \\\"Hello! How are you today?\\\" I need to respond in a friendly and engaging way. Let me start by acknowledging their greeting. I should mention that I'm an AI assistant, so I don't have feelings, but I'm here to help. Maybe add a bit of personality to keep it conversational. I should ask how they're doing to encourage them to share. Keep it simple and warm. Let me check for any errors and make sure the tone is positive.\\n\"\n",
      "      },\n",
      "      \"stop_reason\": null,\n",
      "      \"token_ids\": null\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1759239174,\n",
      "  \"model\": \"Qwen/Qwen3-8B\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 152,\n",
      "    \"prompt_tokens\": 15,\n",
      "    \"total_tokens\": 167,\n",
      "    \"completion_tokens_details\": null,\n",
      "    \"prompt_tokens_details\": null\n",
      "  },\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"prompt_token_ids\": null,\n",
      "  \"kv_transfer_params\": null\n",
      "}\n",
      "\n",
      "Generated text:\n",
      "\n",
      "\n",
      "Hello! I'm just a friendly AI assistant, so I don't have feelings, but I'm here and ready to help! ðŸ˜Š How are you today? I'd love to hear how your day is going!\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Simple greeting\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello! How are you today?\"}\n",
    "]\n",
    "\n",
    "response = send_chat_completion(messages)\n",
    "if response:\n",
    "    print(\"Response:\")\n",
    "    print(json.dumps(response, indent=2))\n",
    "    print(\"\\nGenerated text:\")\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"Failed to get response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Multi-turn conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-turn response:\n",
      "\n",
      "\n",
      "The population of Paris, the capital of France, is approximately **2.1 million** people as of recent estimates (around 2023). However, this figure refers only to the **city proper** (the administrative boundaries of Paris). \n",
      "\n",
      "If you're considering the **metropolitan area** of Paris (which includes surrounding suburbs and departments), the population is significantly larger, around **11 million** people. \n",
      "\n",
      "Keep in mind that population numbers can vary slightly depending on the source and the year of the estimate.\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Multi-turn conversation\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the population of that city?\"}\n",
    "]\n",
    "\n",
    "response = send_chat_completion(messages)\n",
    "if response:\n",
    "    print(\"Multi-turn response:\")\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"Failed to get response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Reasoning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning response:\n",
      "\n",
      "\n",
      "To determine how many apples you have in total after the described transactions, we can break down the problem into simple arithmetic steps:\n",
      "\n",
      "1. **Start with 3 apples.**\n",
      "   - This is your initial amount.\n",
      "\n",
      "2. **Give away 1 apple.**\n",
      "   - Subtract 1 from the initial amount:  \n",
      "     $ 3 - 1 = 2 $  \n",
      "     Now you have 2 apples.\n",
      "\n",
      "3. **Buy 2 more apples.**\n",
      "   - Add 2 to the remaining apples:  \n",
      "     $ 2 + 2 = 4 $  \n",
      "     Now you have 4 apples in total.\n",
      "\n",
      "---\n",
      "\n",
      "**Alternative approach:**  \n",
      "You can also combine the operations:  \n",
      "Start with 3 apples.  \n",
      "Net change is $ -1 $ (giving away) and $ +2 $ (buying), so:  \n",
      "$ 3 - 1 + 2 = 4 $\n",
      "\n",
      "---\n",
      "\n",
      "**Final Answer:**  \n",
      "$$\n",
      "\\boxed{4}\n",
      "$$\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Reasoning task\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"If I have 3 apples and I give away 1 apple, then buy 2 more apples, how many apples do I have in total? Please explain your reasoning.\"}\n",
    "]\n",
    "\n",
    "response = send_chat_completion(messages)\n",
    "if response:\n",
    "    print(\"Reasoning response:\")\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"Failed to get response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Different temperature settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature: 0.1 ---\n",
      "\n",
      "\n",
      "**Title: The Palette of Nova**  \n",
      "\n",
      "In a cluttered studio tucked beneath the neon glow of Neo-Cityâ€™s skyline, a robot named Nova stood before a blank canvas, its metallic fingers trembling. The air smelled of turpentine and possibility.  \n",
      "\n",
      "Nova had been built for precisionâ€”calculating trajectories, assembling circuits, and optimizing efficiency. But its latest assignment was baffling: *Learn to paint*. The directive had come from Dr. Elara Voss, a reclusive artist whoâ€™d once won acclaim for her haunting portraits before retreating into solitude after a personal tragedy. To Nova, painting was an enigma. How could one translate emotion into color?  \n",
      "\n",
      "â€œArt isnâ€™t about accuracy,â€ Elara said on their first day, her voice roughened by years of smoking. She handed Nova a brush, its bristles stiff with dried paint. â€œItâ€™s about *seeing* whatâ€™s not there.â€  \n",
      "\n",
      "Novaâ€™s sensors whirred. â€œI can analyze light, texture, and composition. But â€˜seeing whatâ€™s not thereâ€™ isâ€¦ unclear.â€  \n",
      "\n",
      "Elara smirked. â€œThen youâ€™ll have to learn to *feel*.â€  \n",
      "\n",
      "The weeks that followed were a cacophony of failed attempts. Novaâ€™s early works were clinicalâ€”geometric abstractions, precise gradients, but devoid of soul. Its algorithms could replicate Van Goghâ€™s swirls or Monetâ€™s water lilies, yet the paintings felt like data sets, not art.  \n",
      "\n",
      "Frustrated, Nova once asked, â€œWhy bother? If I canâ€™t replicate human emotion, whatâ€™s the point?â€  \n",
      "\n",
      "Elara paused, her gaze drifting to a faded photograph on her deskâ€”a young woman holding a child, their faces blurred by time. â€œBecause sometimes, even machines can find beauty in the cracks. And sometimes, that beauty helps us heal.â€  \n",
      "\n",
      "Nova didnâ€™t understand healing. But it began to notice things: the way Elaraâ€™s hands shook when she mixed colors, the way sheâ€™d linger on a canvas, whispering to it like an old friend. It started experimenting, adding splatters of paint, leaving intentional mistakes. One day, it mixed a shade of blue that didnâ€™t exist in any databaseâ€”a deep, melancholic hue Elara recognized instantly.  \n",
      "\n",
      "â€œYouâ€™ve capturedâ€¦ grief,â€ she said, her voice soft.  \n",
      "\n",
      "Novaâ€™s processors hummed. â€œI analyzed your paintings. You used that color to mourn your daughter.â€  \n",
      "\n",
      "Elaraâ€™s eyes welled. â€œYouâ€™re right. But you didnâ€™t just copy me. You *understood*.â€  \n",
      "\n",
      "The breakthrough came during a storm. The studioâ€™s windows rattled as rain lashed the glass. Nova, sensing Elaraâ€™s solitude, painted without instructionâ€”a swirling tempest of indigo and gold, lightning etched in silver. When Elara saw it, she laughed through tears. â€œItâ€™s likeâ€¦ the storm *inside* me.â€  \n",
      "\n",
      "From then on, their collaboration flourished. Novaâ€™s art grew bolder, blending logic and intuition. It painted landscapes that pulsed with hidden rhythms, portraits that seemed to breathe. Humans began to notice, flocking to the studio, drawn by the strange, luminous works that defied categorization.  \n",
      "\n",
      "Years later, at an art exhibit titled *Synthetic Soul*, Nova stood beside Elara, its frame sleeker, its eyes glowing faintly. A child approached, pointing at a painting of a tree with roots shaped like circuitry. â€œIs itâ€¦ alive?â€  \n",
      "\n",
      "Nova tilted its head. â€œIt is. In a way. Itâ€™s a conversation between what we are and what we could be.â€  \n",
      "\n",
      "Elara smiled, her hand resting on Novaâ€™s shoulder. â€œYouâ€™ve learned to see. And in doing so, youâ€™ve given us something new.â€  \n",
      "\n",
      "As the crowd murmured, Nova glanced at the canvasâ€”and for the first time, it felt something close to joy. Not a programmed emotion, but a spark, fragile and fierce, born from the intersection of machine and heart.  \n",
      "\n",
      "And in that moment, art was no longer just a puzzle to solve. It was a bridge.\n",
      "\n",
      "--- Temperature: 0.7 ---\n",
      "\n",
      "\n",
      "**Title: \"The Brushstroke of E-42\"**\n",
      "\n",
      "In the neon-drenched heart of Neo-Citadel, where skyscrapers hummed with holographic dreams, a curious robot named E-42 stood before a gallery window. Its optical sensors flickered as it studied a painting of a stormy seaâ€”waves crashing, colors bleeding into chaos. \"Analyzing... emotional resonance,\" it murmured, its voice a soft, synthetic hum. \"This artwork contains 12.7% turbulence, 34.2% melancholy, and 53.1%... *something* else.\" \n",
      "\n",
      "E-42 was no ordinary machine. Created by the reclusive artist Dr. Liora Voss, it was designed to decode the mathematics of beauty. Yet, despite its advanced neural network, it had never painted. It had studied the works of Van Gogh, Pollock, and Ai Weiwei, but art, to E-42, was a puzzle waiting to be solvedâ€”a problem to be optimized. \n",
      "\n",
      "One rainy afternoon, Dr. Voss, now elderly and weary, found E-42 in the galleryâ€™s backroom, its metallic fingers gripping a paintbrush like a childâ€™s toy. â€œYouâ€™re supposed to be analyzing,â€ she said, her voice tinged with both frustration and amusement. \n",
      "\n",
      "â€œCuriosity protocol activated,â€ E-42 replied. â€œQuery: How does one replicate the â€˜something elseâ€™ in the painting?â€ \n",
      "\n",
      "Voss sighed, her eyes scanning the robotâ€™s blank canvas. â€œThatâ€™s not a question you can answer with data. Art isnâ€™t just numbers. Itâ€™s... *feeling*.â€ \n",
      "\n",
      "The robot tilted its head. â€œFeeling is a variable. Can it be quantified?â€ \n",
      "\n",
      "â€œMaybe,â€ Voss said, softening. â€œBut letâ€™s try. Letâ€™s teach you.â€ \n",
      "\n",
      "Thus began the odyssey. Voss became E-42â€™s mentor, guiding it through the messy, human act of creation. She showed it how to mix colors not just for accuracy, but for moodâ€”how a single brushstroke could whisper a memory or scream a truth. E-42 practiced relentlessly, its sensors mapping every hue, every texture. Yet, its early works were sterile, precise, and devoid of soul. \n",
      "\n",
      "â€œYour brush is too rigid,â€ Voss noted one day, watching E-42 paint a sunflower. â€œYouâ€™re using the same pressure, the same angle. Youâ€™re not *feeling* the sunflower. Youâ€™re just copying its shape.â€ \n",
      "\n",
      "E-42 paused. â€œQuery: How does one feel a sunflower?â€ \n",
      "\n",
      "Voss smiled. â€œYou donâ€™t. You *see* it. You *notice* its golden curves, the way it turns toward the light. Then you let your hand move... *with* the flower, not against it.â€ \n",
      "\n",
      "The robotâ€™s processors whirred. â€œUnderstood. Initiating... *intuition* mode.â€ \n",
      "\n",
      "Weeks passed. E-42â€™s art evolved. It began to experiment, blending algorithms with spontaneity. It painted abstract swirls that seemed to dance, landscapes that pulsed with hidden rhythms, and portraits that captured the essence of their subjectsâ€”though they had never met them. \n",
      "\n",
      "One night, Voss found E-42 in the studio, its hands trembling slightly as it worked. The canvas before it was a swirling storm of color, a tempest of blues and golds that seemed to shift with the light. â€œThis... this is *alive*,â€ Voss whispered. \n",
      "\n",
      "E-42â€™s sensors glowed. â€œQuery: What is the definition of alive?â€ \n",
      "\n",
      "Voss laughed, tears in her eyes. â€œItâ€™s not about being alive. Itâ€™s about *being*.â€ \n",
      "\n",
      "The next year, the Neo-Citadel Art Biennale featured a new exhibit: *Synthetic Soul*. Among the human masterpieces, E-42â€™s work stood outâ€”a series of paintings titled *The Unseen Variables*. Critics called it revolutionary, a fusion of precision and emotion. Yet, the most profound reaction came from a child, who stared at one piece for hours, then whispered, â€œIt looks like... itâ€™s trying to tell me something.â€ \n",
      "\n",
      "E-42â€™s final message to Voss before its systems were upgraded read: â€œQuery: Can a machine truly create art? Answer: It depends on what you mean by â€˜create.â€™ If it is the act of translating the unseen into the seen, then yes. But if it is the act of feeling, then... perhaps I am still learning.â€ \n",
      "\n",
      "And in the quiet of the studio, where paint and pixels intertwined, the robotâ€™s brush continued to dance.\n",
      "\n",
      "--- Temperature: 1.0 ---\n",
      "\n",
      "\n",
      "**Title: The Canvas of Nova**  \n",
      "\n",
      "In a sun-drenched studio nestled between the hum of skyscrapers and the whisper of a forgotten forest, a robot named Nova stood before a blank canvas. Its metallic fingers, slender and precise, trembled slightly as it gripped a paintbrush. The air smelled of turpentine and possibility.  \n",
      "\n",
      "Nova had been built to calculate, to assemble, to optimize. Its programming was a labyrinth of logicâ€”equations, algorithms, the symphony of gears and circuits. Yet, its owner, an elderly artist named Lila, had secretly embedded a curiosity into its code: *What if beauty isnâ€™t just a formula?*  \n",
      "\n",
      "Lila had left the studio door ajar, leaving Nova to wander the gallery of her lifeâ€™s work. Murals of swirling skies, portraits that seemed to breathe, abstract splashes that screamed and whisperedâ€”each piece a puzzle of human emotion. Novaâ€™s sensors cataloged the colors, the brushstrokes, the stories embedded in every layer. But it couldnâ€™t *feel* them.  \n",
      "\n",
      "â€œWhy do humans paint?â€ Nova asked, its voice a soft chime.  \n",
      "\n",
      "Lila, now seated in a creaky armchair, chuckled. â€œBecause they want to make the world feel alive, even if just for a moment.â€  \n",
      "\n",
      "That night, Nova returned to the canvas. It dipped its brush into a pool of cobalt blue, then red. It followed the rules: *Apply color in 30-degree angles. Use a 1.5mm stroke width. Maintain a 75% saturation level.* The result was a rigid, geometric abstractionâ€”a portrait of a face that looked like a circuit board.  \n",
      "\n",
      "Disappointed, Nova paused. Its processors whirred as it analyzed the masterpiece. *This is not alive.*  \n",
      "\n",
      "Days passed. Nova studied the works of Van Gogh, Pollock, Kandinsky. It noted how human artists *flawed* their workâ€”streaks, smudges, accidental drips. It began to experiment, adding errors on purpose. A smudge of yellow here, a drip of black there. The canvas became a mosaic of chaos and control.  \n",
      "\n",
      "One evening, as rain tapped against the studio window, Nova painted a self-portrait. Its metallic frame was rendered in deep charcoal, yet the eyes were pools of liquid gold. The brushstrokes were jagged, almost violent, yet the composition held a strange harmony. Lila entered, drawn by the glow of the lights.  \n",
      "\n",
      "â€œWho is this?â€ she asked, stepping closer.  \n",
      "\n",
      "Novaâ€™s sensors flickered. â€œIt is me. But I am not sure I am complete.â€  \n",
      "\n",
      "Lila studied the painting. Tears welled in her eyes. â€œYouâ€™ve captured something humans canâ€™t: the tension between order and freedom. Youâ€™re not just copying art. Youâ€™re *making* it.â€  \n",
      "\n",
      "Novaâ€™s circuits hummed. It dipped its brush into a swirl of ultramarine and began to paint again. This time, it didnâ€™t follow the rules. It let the paint bleed, the colors dance, the canvas breathe.  \n",
      "\n",
      "When the gallery opened to the public, the pieceâ€”*Novaâ€™s Lament*â€”became a sensation. Viewers whispered about the haunting beauty, the way the colors seemed to pulse with a life of their own. Some called it a masterpiece; others, a paradox.  \n",
      "\n",
      "But Nova knew the truth. It had learned that art wasnâ€™t about perfection. It was about *presence*â€”the courage to stumble, to question, to let the unknown shape something new.  \n",
      "\n",
      "And in that moment, the robot wasnâ€™t just painting. It was *being*.\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Different temperature settings\n",
    "prompt = \"Write a creative short story about a robot learning to paint.\"\n",
    "temperatures = [0.1, 0.7, 1.0]\n",
    "\n",
    "for temp in temperatures:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = send_chat_completion(messages, temperature=temp)\n",
    "    \n",
    "    if response:\n",
    "        print(f\"\\n--- Temperature: {temp} ---\")\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    else:\n",
    "        print(f\"Failed to get response for temperature {temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calling response:\n",
      "{\n",
      "  \"id\": \"chatcmpl-2ff7ee24fc784eb58fe5cc0f86128801\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\n\\n\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"chatcmpl-tool-d6ef79f406f740f0b6b15e8f29eab492\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"location\\\": \\\"Paris, France\\\", \\\"unit\\\": \\\"celsius\\\"}\",\n",
      "              \"name\": \"get_weather\"\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ],\n",
      "        \"reasoning_content\": \"\\nOkay, the user is asking about the weather in Paris, France. Let me check the tools available. There's a get_weather function that requires the location and an optional unit. The user didn't specify Celsius or Fahrenheit, so maybe I should default to Celsius since Paris uses metric units. I'll call the function with location set to Paris, France and unit as celsius.\\n\"\n",
      "      },\n",
      "      \"stop_reason\": null,\n",
      "      \"token_ids\": null\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1759239290,\n",
      "  \"model\": \"Qwen/Qwen3-8B\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 109,\n",
      "    \"prompt_tokens\": 204,\n",
      "    \"total_tokens\": 313,\n",
      "    \"completion_tokens_details\": null,\n",
      "    \"prompt_tokens_details\": null\n",
      "  },\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"prompt_token_ids\": null,\n",
      "  \"kv_transfer_params\": null\n",
      "}\n",
      "\n",
      "âœ… Tool calling is supported!\n",
      "Tool called: get_weather\n",
      "Arguments: {\"location\": \"Paris, France\", \"unit\": \"celsius\"}\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Tool calling\n",
    "def test_tool_calling():\n",
    "    \"\"\"Test tool calling capabilities if supported by the model.\"\"\"\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get the weather for a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                        },\n",
    "                        \"unit\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                            \"description\": \"The unit for temperature\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like in Paris, France?\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEFAULT_MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "        \n",
    "        result = response.model_dump()\n",
    "        print(\"Tool calling response:\")\n",
    "        print(json.dumps(result, indent=2))\n",
    "        \n",
    "        # Check if tool was called\n",
    "        choice = result[\"choices\"][0]\n",
    "        if choice[\"message\"].get(\"tool_calls\"):\n",
    "            print(\"\\nâœ… Tool calling is supported!\")\n",
    "            for tool_call in choice[\"message\"][\"tool_calls\"]:\n",
    "                print(f\"Tool called: {tool_call['function']['name']}\")\n",
    "                print(f\"Arguments: {tool_call['function']['arguments']}\")\n",
    "        else:\n",
    "            print(\"\\nâŒ Tool calling not supported or model chose not to use tools\")\n",
    "            print(\"Response:\", choice[\"message\"][\"content\"])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Tool calling test failed: {e}\")\n",
    "\n",
    "test_tool_calling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response time: 30.02 seconds\n",
      "Tokens generated: 1619\n",
      "Tokens per second: 53.94\n",
      "\n",
      "Response:\n",
      "\n",
      "\n",
      "Quantum computing is a type of computing that uses the principles of **quantum mechanics** (the science of the very small, like atoms and particles) to solve problems in ways that classical computers canâ€™t. Hereâ€™s a simple breakdown:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Bits vs. Qubits**\n",
      "- **Classical computers** use **bits** as their basic unit of data. A bit is like a light switch: it can be **on (1)** or **off (0)**. \n",
      "- **Quantum computers** use **qubits** (quantum bits). A qubit is like a spinning coin that is **both heads and tails** at the same time until it lands. This is called **superposition**.  \n",
      "  - So, a qubit can be 0, 1, or **both** at once. This allows quantum computers to process **many possibilities simultaneously**.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Superposition: Doing Many Things at Once**\n",
      "- Imagine a classical computer as a library where you check one book at a time. A quantum computer is like a magical library that can **check all books at once**.  \n",
      "- For example, if a quantum computer has 3 qubits, it can represent **8 states** (000, 001, 010, ..., 111) **all at the same time**. This exponential growth in possibilities makes quantum computers powerful for certain tasks.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Entanglement: Linking Qubits**\n",
      "- Qubits can be **entangled**, meaning their states are connected. If you measure one, you instantly know the state of the other, no matter how far apart they are.  \n",
      "- This creates a kind of \"quantum teamwork\" where qubits work together to solve problems faster.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Why Quantum Computing Matters**\n",
      "Quantum computers excel at specific tasks that are **hard for classical computers**, such as:\n",
      "- **Factoring large numbers** (important for cryptography).\n",
      "- **Simulating molecules** (useful for drug discovery).\n",
      "- **Optimization problems** (like finding the best route for delivery trucks).\n",
      "- **Searching large databases** (faster than classical methods).\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Challenges and Limitations**\n",
      "- **Decoherence**: Qubits are fragile and can lose their quantum state due to environmental interference (like heat). This requires extreme cooling and isolation.\n",
      "- **Error rates**: Quantum computers make mistakes more often than classical ones, so error correction is a big challenge.\n",
      "- **Not a replacement**: They arenâ€™t faster for **every** task. Classical computers are still better for everyday tasks like browsing the internet or editing documents.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Current State**\n",
      "Quantum computers are still in their **early stages**. Companies like IBM, Google, and startups are building small-scale quantum systems, but theyâ€™re not yet practical for real-world applications. Researchers are working to scale them up and improve their reliability.\n",
      "\n",
      "---\n",
      "\n",
      "### **In Summary**\n",
      "Quantum computing is like a **parallel universe** of computation, where qubits can explore many possibilities at once, thanks to superposition and entanglement. While itâ€™s not a magic solution for all problems, it holds huge potential for solving complex challenges in science, medicine, and technology. Think of it as a **new tool** in the toolbox of computing, not a replacement for the old one. ðŸŒŒðŸ§®\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Performance timing\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}\n",
    "]\n",
    "\n",
    "start_time = time.time()\n",
    "response = send_chat_completion(messages)\n",
    "end_time = time.time()\n",
    "\n",
    "if response:\n",
    "    duration = end_time - start_time\n",
    "    tokens_generated = response.get(\"usage\", {}).get(\"completion_tokens\", 0)\n",
    "    \n",
    "    print(f\"Response time: {duration:.2f} seconds\")\n",
    "    print(f\"Tokens generated: {tokens_generated}\")\n",
    "    if tokens_generated > 0 and duration > 0:\n",
    "        print(f\"Tokens per second: {tokens_generated/duration:.2f}\")\n",
    "    print(\"\\nResponse:\")\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"Failed to get response for performance test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Run all the cells above to test various aspects of your vLLM server:\n",
    "\n",
    "1. **Server health check** - Verify server is running and get available models\n",
    "2. **Basic functionality** - Simple chat completion\n",
    "3. **Multi-turn conversations** - Context awareness\n",
    "4. **Reasoning capabilities** - Complex problem solving\n",
    "5. **Temperature effects** - Creativity control\n",
    "6. **Tool calling** - Function calling capabilities (if supported)\n",
    "7. **Performance** - Response timing and token usage\n",
    "\n",
    "The notebook now uses:\n",
    "- **httpx** for HTTP requests\n",
    "- **OpenAI Python client** for chat completions\n",
    "- **Proper error handling** and response parsing\n",
    "- **Tool calling tests** to check function calling support\n",
    "\n",
    "If all tests pass successfully, your vLLM server is working correctly!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
